{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1850fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        80\n",
      "           1       1.00      0.99      1.00       102\n",
      "\n",
      "    accuracy                           0.99       182\n",
      "   macro avg       0.99      1.00      0.99       182\n",
      "weighted avg       0.99      0.99      0.99       182\n",
      "\n",
      "âœ… Accuracy: 99.45 %\n",
      "\n",
      "ðŸ§  Sample Confidence Predictions:\n",
      "                                                 Text  True Label  Predicted  \\\n",
      "0  perfect it started raining right after i washe...           1          1   \n",
      "1           looking forward to my vacation next week           0          0   \n",
      "2           i had a great time with my friends today           0          0   \n",
      "3                 the concert last night was amazing           0          1   \n",
      "4           i had a great time with my friends today           0          1   \n",
      "5  yeah because nothing says fun like doing taxes...           1          1   \n",
      "6           i had a great time with my friends today           0          1   \n",
      "7   great another meeting that couldve been an email           1          0   \n",
      "8            i enjoyed watching the movie last night           0          1   \n",
      "9           oh joy another ad before my video starts           1          0   \n",
      "\n",
      "   Sarcasm Confidence (%)  \n",
      "0                   100.0  \n",
      "1                     0.0  \n",
      "2                     0.0  \n",
      "3                   100.0  \n",
      "4                   100.0  \n",
      "5                   100.0  \n",
      "6                   100.0  \n",
      "7                     0.0  \n",
      "8                   100.0  \n",
      "9                     0.0  \n",
      "\n",
      "âœ… Model and vectorizer saved successfully as 'model.pkl' and 'vectorizer.pkl'!\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ðŸ’¬ Smart Sarcasm Detector - Model Training (with Confidence Scores)\n",
    "# ================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"sarcasm.csv\")\n",
    "df.rename(columns={\"tweet\": \"text\", \"is_sarcastic\": \"label\"}, inplace=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Clean text\n",
    "# -----------------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|[^a-z\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"clean_tweet\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature extraction\n",
    "# -----------------------------\n",
    "def extract_features(text):\n",
    "    cues = [\n",
    "        \"yeah right\", \"sure\", \"obviously\", \"totally\", \"great\", \"love\", \"perfect\",\n",
    "        \"amazing\", \"as if\", \"just what i needed\", \"oh wonderful\", \"thanks a lot\"\n",
    "    ]\n",
    "    cue_present = int(any(cue in text for cue in cues))\n",
    "    contrast = int(any(w in text for w in [\"not\", \"but\", \"though\", \"however\", \"although\"]))\n",
    "    return [cue_present, contrast]\n",
    "\n",
    "def irony_features(text):\n",
    "    pos_words = ['love', 'great', 'amazing', 'wonderful', 'happy', 'perfect', 'nice', 'enjoy']\n",
    "    neg_words = ['boring', 'bad', 'hate', 'terrible', 'worst', 'ugly', 'awful', 'sad']\n",
    "    polite = ['ok', 'fine', 'thanks', 'good']\n",
    "    rude = ['stupid', 'bad', 'dumb', 'ugly', 'taste']\n",
    "\n",
    "    pos_neg_mix = int(any(p in text for p in pos_words) and any(n in text for n in neg_words))\n",
    "    polite_rude_mix = int(any(p in text for p in polite) and any(r in text for r in rude))\n",
    "    self_neg = int('i' in text and any(w in text for w in ['not','donâ€™t','never','no']))\n",
    "\n",
    "    words = text.split()\n",
    "    flip = 0\n",
    "    for i in range(1,len(words)):\n",
    "        if any(w in words[i-1] for w in pos_words) and any(w in words[i] for w in neg_words): \n",
    "            flip = 1\n",
    "            break\n",
    "        if any(w in words[i-1] for w in neg_words) and any(w in words[i] for w in pos_words): \n",
    "            flip = 1\n",
    "            break\n",
    "\n",
    "    return [pos_neg_mix, polite_rude_mix, self_neg, flip]\n",
    "\n",
    "# Compute handcrafted features\n",
    "extra_features = np.array([extract_features(t) + irony_features(t) for t in df[\"clean_tweet\"]])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Train-test split\n",
    "# -----------------------------\n",
    "X_train_text, X_test_text, y_train, y_test, X_train_extra, X_test_extra = train_test_split(\n",
    "    df[\"clean_tweet\"], df[\"label\"], extra_features, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)\n",
    "\n",
    "X_train_combined = np.hstack([X_train_tfidf.toarray(), X_train_extra])\n",
    "X_test_combined = np.hstack([X_test_tfidf.toarray(), X_test_extra])\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Train model\n",
    "# -----------------------------\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Evaluate with confidence\n",
    "# -----------------------------\n",
    "y_pred = model.predict(X_test_combined)\n",
    "y_prob = model.predict_proba(X_test_combined)\n",
    "\n",
    "# Confidence score for sarcastic class (class 1)\n",
    "confidences = (y_prob[:, 1] * 100).round(2)\n",
    "\n",
    "print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"âœ… Accuracy:\", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")\n",
    "\n",
    "# Example of confidence preview\n",
    "sample_results = pd.DataFrame({\n",
    "    \"Text\": X_test_text.sample(10, random_state=42).values,\n",
    "    \"True Label\": y_test.sample(10, random_state=42).values,\n",
    "    \"Predicted\": y_pred[:10],\n",
    "    \"Sarcasm Confidence (%)\": confidences[:10]\n",
    "})\n",
    "print(\"\\nðŸ§  Sample Confidence Predictions:\\n\", sample_results)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save model and vectorizer\n",
    "# -----------------------------\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "print(\"\\nâœ… Model and vectorizer saved successfully as 'model.pkl' and 'vectorizer.pkl'!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarcasm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
